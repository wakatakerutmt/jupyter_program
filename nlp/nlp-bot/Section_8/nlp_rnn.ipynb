{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNによる自然言語処理\n",
    "RNNを使って、文書の自動作成を行います。  \n",
    "今回は、江戸川乱歩の「怪人二十面相」を学習データに使い、乱歩風の文章を自動生成します。  \n",
    "文章における文字の並びを時系列データと捉えて、次の文字を予測するようにRNNを訓練します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキストデータの前処理\n",
    "今回は、学習データとして青空文庫の「怪人二十面相」を使います。  \n",
    "最初に、テキストデータに前処理を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open(\"kaijin_nijumenso.txt\", mode=\"r\", encoding=\"utf-8\") as f:  # ファイルの読み込み\n",
    "    text_original = f.read()\n",
    "\n",
    "text = re.sub(\"《[^》]+》\", \"\", text_original) # ルビの削除\n",
    "text = re.sub(\"［[^］]+］\", \"\", text) # 読みの注意の削除\n",
    "text = re.sub(\"[｜ 　]\", \"\", text) # | と全角半角スペースの削除\n",
    "print(\"文字数\", len(text))  # len() で文字列の文字数も取得可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各設定\n",
    "RNNの各設定です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rnn = 10  # 時系列の数\n",
    "batch_size = 128\n",
    "epochs = 60\n",
    "n_mid = 128  # 中間層のニューロン数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文字のベクトル化\n",
    "各文字をone-hot表現で表し、時系列の入力データおよび正解データを作成します。  \n",
    "今回はRNNの最後の時刻の出力のみ利用するので、最後の出力に対応する正解のみ必要になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# インデックスと文字で辞書を作成\n",
    "chars = sorted(list(set(text)))  # setで文字の重複をなくし、各文字をリストに格納する\n",
    "print(\"文字数（重複無し）\", len(chars))\n",
    "char_indices = {}  # 文字がキーでインデックスが値\n",
    "for i, char in enumerate(chars):\n",
    "    char_indices[char] = i\n",
    "indices_char = {}  # インデックスがキーで文字が値\n",
    "for i, char in enumerate(chars):\n",
    "    indices_char[i] = char\n",
    " \n",
    "# 時系列データと、それから予測すべき文字を取り出します\n",
    "time_chars = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - n_rnn):\n",
    "    time_chars.append(text[i: i + n_rnn])\n",
    "    next_chars.append(text[i + n_rnn])\n",
    " \n",
    "# 入力と正解をone-hot表現で表します\n",
    "x = np.zeros((len(time_chars), n_rnn, len(chars)), dtype=np.bool)\n",
    "t = np.zeros((len(time_chars), len(chars)), dtype=np.bool)\n",
    "for i, t_cs in enumerate(time_chars):\n",
    "    t[i, char_indices[next_chars[i]]] = 1  # 正解をone-hot表現で表す\n",
    "    for j, char in enumerate(t_cs):\n",
    "        x[i, j, char_indices[char]] = 1  # 入力をone-hot表現で表す\n",
    "        \n",
    "print(\"xの形状\", x.shape)\n",
    "print(\"tの形状\", t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの構築\n",
    "Kerasを使ってRNNを構築します。  \n",
    "今回も、SimpleRNN層を使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(n_mid, input_shape=(n_rnn, len(chars))))\n",
    "model.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文書生成用の関数\n",
    "各エポックの終了後、文章を生成するための関数を記述します。  \n",
    "LambdaCallbackを使って、エポック終了時に実行される関数を設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    " \n",
    "def on_epoch_end(epoch, logs):\n",
    "    print(\"エポック: \", epoch)\n",
    "\n",
    "    beta = 5  # 確率分布を調整する定数\n",
    "    prev_text = text[0:n_rnn]  # 入力に使う文字\n",
    "    created_text = prev_text  # 生成されるテキスト\n",
    "    \n",
    "    print(\"シード: \", created_text)\n",
    "\n",
    "    for i in range(400):\n",
    "        # 入力をone-hot表現に\n",
    "        x_pred = np.zeros((1, n_rnn, len(chars)))\n",
    "        for j, char in enumerate(prev_text):\n",
    "            x_pred[0, j, char_indices[char]] = 1\n",
    "        \n",
    "        # 予測を行い、次の文字を得る\n",
    "        y = model.predict(x_pred)\n",
    "        p_power = y[0] ** beta  # 確率分布の調整\n",
    "        next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power))        \n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        created_text += next_char\n",
    "        prev_text = prev_text[1:] + next_char\n",
    "\n",
    "    print(created_text)\n",
    "    print()\n",
    "\n",
    "# エポック終了後に実行される関数を設定\n",
    "epock_end_callback= LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "構築したモデルを使って、学習を行います。  \n",
    "fit( )メソッドをではコールバックの設定をし、エポック終了後に関数が呼ばれるようにします。  \n",
    "学習には数十分程度かかるので、時間のない方はエポック数を少なくして実行しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x, t,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[epock_end_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一見すると乱歩の文体のようにも見えますが、まだ意味を成していませんね。  \n",
    "SimpleRNNでは過去の文脈を利用するのが難しいのですが、後々セクションで扱うLSTMを使えばより自然な文章に改善するかもしれません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の推移\n",
    "誤差の推移を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "plt.plot(np.arange(len(loss)), loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "誤差はまだ収束していないので、さらにエポック数を重ねることにより結果は改善しそうです。  \n",
    "今回は文書を自動で生成しましたが、同様にしてRNNを自動作曲などに応用することも可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題\n",
    "青空文庫の「銀河鉄道の夜」を読み込み、宮沢賢治風の文章を自動生成してみましょう。  \n",
    "このノートブックと同じフォルダに、以下のファイルがあります。  \n",
    "gingatetsudono_yoru.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
