{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 対話コーパスの前処理\n",
    "以降のレクチャーでは、Seq2Seqを使って対話文を生成します。  \n",
    "宮沢賢治の小説を学習データに使い、賢治風の返事ができるようにモデルを訓練します。  \n",
    "今回は、そのための準備として、コーパスに前処理を行います。  \n",
    "小規模なコーパスでも対話文が生成ができるように、漢字は全てひらがなに変換します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキストデータの前処理\n",
    "今回は、宮沢賢治の小説「銀河鉄道の夜」「セロ弾きのゴーシュ」「注文の多い料理店」などをコーパスとします。  \n",
    "コーパスが大きほど精度が高まるのですが、学習に時間がかかり過ぎても本コースに支障があるので、10作品に抑えておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "novels = [\"gingatetsudono_yoru.txt\", \"serohikino_goshu.txt\", \"chumonno_oi_ryoriten.txt\",\n",
    "         \"gusukobudorino_denki.txt\", \"kaeruno_gomugutsu.txt\", \"kaino_hi.txt\", \"kashiwabayashino_yoru.txt\",\n",
    "         \"kazeno_matasaburo.txt\", \"kiirono_tomato.txt\", \"oinomorito_zarumori.txt\"]  # 青空文庫より\n",
    "\n",
    "text = \"\"\n",
    "for novel in novels:\n",
    "    with open(\"kenji_novels/\"+novel, mode=\"r\", encoding=\"utf-8\") as f:  # ファイルの読み込み\n",
    "        text_novel = f.read()\n",
    "    text_novel = re.sub(\"《[^》]+》\", \"\", text_novel)  # ルビの削除\n",
    "    text_novel = re.sub(\"［[^］]+］\", \"\", text_novel)  # 読みの注意の削除\n",
    "    text_novel = re.sub(\"〔[^〕]+〕\", \"\", text_novel)  # 読みの注意の削除\n",
    "    text_novel = re.sub(\"[ 　\\n「」『』（）｜※＊…]\", \"\", text_novel)  # 全角半角スペース、改行、その他記号の削除\n",
    "    text += text_novel\n",
    "\n",
    "print(\"文字数:\", len(text))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 漢字をひらがなに変換\n",
    "漢字を平仮名に変換し、テキストをひらがな、カタカナ、記号のみにします。  \n",
    "文字数を絞ることで、モデルの精度を上げて学習時間を短くします。  \n",
    "漢字を平仮名に変換するためには、pykakasiというライブラリを使います。  \n",
    "pykakasiがうまく動作しない方は、前処理済みのテキストファイル（kana_kenji.txt）がありますので、それをご利用ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykakasi import kakasi\n",
    "\n",
    "seperator = \"。\"  # 。をセパレータに指定\n",
    "sentence_list = text.split(seperator)  # セパレーターを使って文章をリストに分割する\n",
    "sentence_list.pop() # 最後の要素は空の文字列になるので、削除\n",
    "sentence_list = [x+seperator for x in sentence_list]  # 文章の最後に。を追加\n",
    "\n",
    "kakasi = kakasi()\n",
    "kakasi.setMode(\"J\", \"H\")  # J(漢字) からH(ひらがな)へ\n",
    "conv = kakasi.getConverter()\n",
    "for sentence in sentence_list:\n",
    "    print(sentence)\n",
    "    print(conv.do(sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エラーが発生しました。  \n",
    "pykakasiの辞書に無い「苹」という文字が問題となっているようです。  \n",
    "この文字を予めひらがなに変換した上で、再び変換を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"苹果\", \"ひょうか\")\n",
    "\n",
    "seperator = \"。\"\n",
    "sentence_list = text.split(seperator) \n",
    "sentence_list.pop() \n",
    "sentence_list = [x+seperator for x in sentence_list]\n",
    "\n",
    "for sentence in sentence_list:\n",
    "    print(sentence)\n",
    "    print(conv.do(sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エラーは発生していませんね。  \n",
    "問題なくひらがなに変換できたようです。  \n",
    "\n",
    "次に、set()を使って文字の重複を無くし、使用されている文字の一覧を表示してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kana_text = conv.do(text)  # 全体をひらがなに変換\n",
    "print(set(kana_text))  # set()で文字の重複をなくす"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ひらがなとカタカナ、一部の記号のみが残りました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキストデータの保存\n",
    "テキストデータを保存し、いつでも使えるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kana_text)\n",
    "with open(\"kana_kenji.txt\", mode=\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(kana_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存したテキストファイルを読み込み、保存できていることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"kana_kenji.txt\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    kana_text = f.read()\n",
    "print(kana_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題なく保存できているようですね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題\n",
    "漢字からひらがなへの変換が、不自然である箇所をいくつか探してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
