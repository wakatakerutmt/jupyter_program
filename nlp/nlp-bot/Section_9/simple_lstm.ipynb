{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# シンプルなLSTMの実装\n",
    "LSTM層を用いてシンプルなニューラルネットワークを構築し、時系列データを学習します。  \n",
    "今回は、通常のRNNとLSTMを比較します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練用データの作成\n",
    "訓練用のデータを作成します。  \n",
    "サイン関数に乱数でノイズを加えたデータを作成し、過去の時系列データから未来の値を予測できるようにします。  \n",
    "以前にシンプルなRNNを構築した際と異なり、今回は最後の時刻の出力のみ利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_data = np.linspace(-2*np.pi, 2*np.pi)  # -2πから2πまで\n",
    "sin_data = np.sin(x_data) + 0.1*np.random.randn(len(x_data))  # sin関数に乱数でノイズを加える\n",
    "\n",
    "plt.plot(x_data, sin_data)\n",
    "plt.show()\n",
    "\n",
    "n_rnn = 10  # 時系列の数\n",
    "n_sample = len(x_data)-n_rnn  # サンプル数\n",
    "x = np.zeros((n_sample, n_rnn))  # 入力\n",
    "t = np.zeros((n_sample,))  # 正解、最後の時刻のみ\n",
    "\n",
    "for i in range(0, n_sample):\n",
    "    x[i] = sin_data[i:i+n_rnn]\n",
    "    t[i] = sin_data[i+n_rnn]  # 入力の時系列より一つ後の値\n",
    "\n",
    "x = x.reshape(n_sample, n_rnn, 1)  # （サンプル数、時系列の数、入力層のニューロン数）\n",
    "print(x.shape)\n",
    "t = t.reshape(n_sample, 1)  # （サンプル数、入力層のニューロン数）\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleRNNとLSTMの比較\n",
    "Kerasを使って通常のRNN、およびLSTMを構築します。  \n",
    "Kerasにおいて、LSTM層はSimpleRNN層と同じ方法で追加することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM\n",
    "\n",
    "batch_size = 8  # バッチサイズ\n",
    "n_in = 1  # 入力層のニューロン数\n",
    "n_mid = 20  # 中間層のニューロン数\n",
    "n_out = 1  # 出力層のニューロン数\n",
    "\n",
    "# 比較のための通常のRNN\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(SimpleRNN(n_mid, input_shape=(n_rnn, n_in), return_sequences=False))  # 最後の出力のみ使用\n",
    "model_rnn.add(Dense(n_out, activation=\"linear\"))\n",
    "model_rnn.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "print(model_rnn.summary())\n",
    "\n",
    "# LSTM\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, n_in), return_sequences=False))\n",
    "model_lstm.add(Dense(n_out, activation=\"linear\"))\n",
    "model_lstm.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleRNNよりも、LSTMの方がパラメータがずっと多いですね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "構築したRNNのモデルを使って、学習を行います。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "# 通常のRNN\n",
    "start_time = time.time()\n",
    "history_rnn = model_rnn.fit(x, t, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "print(\"学習時間 --通常のRNN--:\", time.time() - start_time)\n",
    "\n",
    "# LSTM\n",
    "start_time = time.time()\n",
    "history_lstm = model_lstm.fit(x, t, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "print(\"学習時間 --LSTM--:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エポック数が同じ場合、パラメータ数が多いためLSTMの方が学習にずっと時間がかかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の推移\n",
    "誤差の推移を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rnn = history_rnn.history['loss']\n",
    "loss_lstm = history_lstm.history['loss']\n",
    "\n",
    "plt.plot(np.arange(len(loss_rnn)), loss_rnn, label=\"RNN\")\n",
    "plt.plot(np.arange(len(loss_lstm)), loss_lstm, label=\"LSTM\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルが複雑なため、LSTMの方が誤差の収束にエポック数が必要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルの使用\n",
    "それぞれの学習済みモデルを使って、サイン関数の次の値を予測します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rnn = x[0].reshape(-1) \n",
    "predicted_lstm = x[0].reshape(-1) \n",
    "\n",
    "for i in range(0, n_sample):\n",
    "    y_rnn = model_rnn.predict(predicted_rnn[-n_rnn:].reshape(1, n_rnn, 1))\n",
    "    predicted_rnn = np.append(predicted_rnn, y_rnn[0][0])\n",
    "    y_lstm = model_lstm.predict(predicted_lstm[-n_rnn:].reshape(1, n_rnn, 1))\n",
    "    predicted_lstm = np.append(predicted_lstm, y_lstm[0][0])\n",
    "\n",
    "plt.plot(np.arange(len(sin_data)), sin_data, label=\"Training data\")\n",
    "plt.plot(np.arange(len(predicted_rnn)), predicted_rnn, label=\"Predicted_RNN\")\n",
    "plt.plot(np.arange(len(predicted_lstm)), predicted_lstm, label=\"Predicted_LSTM\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMを使ったモデルが、サインカーブを学習できていることが分かります。  \n",
    "\n",
    "このように、LSTMはRNNと同様に時系列データの学習ができるのですが、パラメータ数が多くモデルが複雑なため学習に時間がかかります。  \n",
    "今回の例からはLSTMのメリットはあまり分かりませんが、文脈が大事な自然言語処理などで、LSTMはその真価を発揮します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題\n",
    "サイン関数以外の、様々な関数をLSTMに学習させてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
