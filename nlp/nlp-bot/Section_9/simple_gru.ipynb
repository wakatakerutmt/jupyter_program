{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# シンプルなGRUの実装\n",
    "GRU層を用いてシンプルなニューラルネットワークを構築し、時系列データを学習します。  \n",
    "今回は、LSTMとGRUを比較します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練用データの作成\n",
    "訓練用のデータを作成します。  \n",
    "サイン関数に乱数でノイズを加えたデータを作成し、過去の時系列データから未来の値を予測できるようにします。  \n",
    "今回も、最後の時刻の出力のみ利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_data = np.linspace(-2*np.pi, 2*np.pi)  # -2πから2πまで\n",
    "sin_data = np.sin(x_data) + 0.1*np.random.randn(len(x_data))  # sin関数に乱数でノイズを加える\n",
    "\n",
    "plt.plot(x_data, sin_data)\n",
    "plt.show()\n",
    "\n",
    "n_rnn = 10  # 時系列の数\n",
    "n_sample = len(x_data)-n_rnn  # サンプル数\n",
    "x = np.zeros((n_sample, n_rnn))  # 入力\n",
    "t = np.zeros((n_sample,))  # 正解、最後の時刻のみ\n",
    "\n",
    "for i in range(0, n_sample):\n",
    "    x[i] = sin_data[i:i+n_rnn]\n",
    "    t[i] = sin_data[i+n_rnn]  # 入力の時系列より一つ後の値\n",
    "\n",
    "x = x.reshape(n_sample, n_rnn, 1)  # （サンプル数、時系列の数、入力層のニューロン数）\n",
    "print(x.shape)\n",
    "t = t.reshape(n_sample, 1)  # （サンプル数、入力層のニューロン数）\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMとGRUの比較\n",
    "Kerasを使ってLSTM、およびGRUを構築します。  \n",
    "Kerasにおいて、GRU層はSimpleRNN層やLSTM層と同じ方法で追加することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU\n",
    "\n",
    "batch_size = 8  # バッチサイズ\n",
    "n_in = 1  # 入力層のニューロン数\n",
    "n_mid = 20  # 中間層のニューロン数\n",
    "n_out = 1  # 出力層のニューロン数\n",
    "\n",
    "# 比較のためのLSTM\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, n_in), return_sequences=False))  # 最後の出力のみ使用\n",
    "model_lstm.add(Dense(n_out, activation=\"linear\"))\n",
    "model_lstm.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "print(model_lstm.summary())\n",
    "\n",
    "# GRU\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(n_mid, input_shape=(n_rnn, n_in), return_sequences=False))\n",
    "model_gru.add(Dense(n_out, activation=\"linear\"))\n",
    "model_gru.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "print(model_gru.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMよりも、GRUの方がパラメータが少ないですね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "構築したRNNのモデルを使って、学習を行います。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "# LSTM\n",
    "start_time = time.time()\n",
    "history_lstm = model_lstm.fit(x, t, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "print(\"学習時間 --LSTM--:\", time.time() - start_time)\n",
    "\n",
    "# GRU\n",
    "start_time = time.time()\n",
    "history_gru = model_gru.fit(x, t, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "print(\"学習時間 --GRU--:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エポック数が同じ場合、パラメータ数が少ないためGRUの方が学習に時間がかかりません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の推移\n",
    "誤差の推移を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_lstm = history_lstm.history['loss']\n",
    "loss_gru = history_gru.history['loss']\n",
    "\n",
    "plt.plot(np.arange(len(loss_lstm)), loss_lstm, label=\"LSTM\")\n",
    "plt.plot(np.arange(len(loss_gru)), loss_gru, label=\"GRU\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最初は早く収束するのですが、最終的な収束にはGRUの方がエポック数が必要なようです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルの使用\n",
    "それぞれの学習済みモデルを使って、サイン関数の次の値を予測します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_lstm = x[0].reshape(-1) \n",
    "predicted_gru = x[0].reshape(-1) \n",
    "\n",
    "for i in range(0, n_sample):\n",
    "    y_lstm = model_lstm.predict(predicted_lstm[-n_rnn:].reshape(1, n_rnn, 1))\n",
    "    predicted_lstm = np.append(predicted_lstm, y_lstm[0][0])\n",
    "    y_gru = model_gru.predict(predicted_gru[-n_rnn:].reshape(1, n_rnn, 1))\n",
    "    predicted_gru = np.append(predicted_gru, y_gru[0][0])\n",
    "\n",
    "plt.plot(np.arange(len(sin_data)), sin_data, label=\"Training data\")\n",
    "plt.plot(np.arange(len(predicted_lstm)), predicted_lstm, label=\"Predicted_LSTM\")\n",
    "plt.plot(np.arange(len(predicted_gru)), predicted_gru, label=\"Predicted_GRU\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRUを使ったモデルも、LSTMと同様にサインカーブを学習できていることが分かります。  \n",
    "このグラフでは、LSTMの方がよく収束していますね。\n",
    "\n",
    "このように、GRUはパラメータ数が少なく1エポックに必要な時間は短いのですが、LSTMよりも収束にエポック数が必要な場合があります。  \n",
    "状況に応じて、LSTMとGRUを使い分ける必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題\n",
    "サイン関数以外の、様々な関数をGRUに学習させて、LSTMの結果と比較してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
